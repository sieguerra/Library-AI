# Library-AI
Duke Kunshan University Library AI - Simple Ollama Integration

A simple frontend-backend system for LLM chat using Ollama.

## Setup

1. **Install Ollama**: Download from https://ollama.ai
2. **Pull a model**: `ollama pull llama2` (or any model you prefer)
3. **Start Ollama**: `ollama serve`

## Run the app
```bash
npm run install:all
npm run dev
```

## Services
- Frontend: http://localhost:3000
- Backend: http://localhost:5000
